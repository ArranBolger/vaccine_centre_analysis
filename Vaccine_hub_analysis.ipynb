{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessibility of Ireland's mass vaccine centres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Motivation: there are 37 mass vaccination centres in Ireland. This algorithm aims to measure how accessible they are by public transport."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: importing the data\n",
    "\n",
    "The data for this analysis is stored in 51 different folders, each containing the GTFS files for a different operator. The coordinates for the vaccination centres are also stored in a separate file using a similar format to the GTFS files.\n",
    "\n",
    "For the algorithm to work, the following GTFS files need to be imported as DataFrames, keeping the named columns:\n",
    "\n",
    "1. stops.txt: stop_id, stop_name, stop_lat, stop_lon\n",
    "2. Vaccine_Hubs.txt: acility, facility_lat, facility_lon\n",
    "3. stop_times.txt:trip_id, arrival_time, departure_time, stop_id, stop_sequence, pickup_type, drop_off_type\n",
    "4. trips.txt\n",
    "5. calendar.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from haversine import haversine_vector\n",
    "import time\n",
    "\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "#pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtfs_folder = 'GTFS Files'\n",
    "operators = next(walk(gtfs_folder))[1]\n",
    "\n",
    "MAX_TRANSFER_DIST = 2.0\n",
    "MAX_WALK_DIST = 5.0\n",
    "WALKING_SPEED = 5.0\n",
    "WALK_EFFORT_FACTOR = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1a: import stop location data and identify transfer stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stops = 12614\n",
      "SSSSSSSSSSS\n"
     ]
    }
   ],
   "source": [
    "def import_stops():\n",
    "    stops = []\n",
    "\n",
    "    for operator in operators:\n",
    "        file = gtfs_folder + '\\\\' + operator + '\\\\' + 'stops.txt'\n",
    "        df = pd.read_csv(file)[['stop_id', 'stop_name', 'stop_lat', 'stop_lon']]\n",
    "        stops.append(df)\n",
    "\n",
    "    stops = pd.concat(stops).drop_duplicates('stop_id')  # some stops are used by multiple operators with the same ID, so will be duplicated\n",
    "    stops['merge_key'] = 1\n",
    "    print(\"Number of stops =\", len(stops.index))\n",
    "\n",
    "    transfer_stops = find_nearby_stops(stops)\n",
    "    transfer_stops = transfer_stops[transfer_stops.transfer_distance < MAX_TRANSFER_DIST]\n",
    "    transfer_stops['transfer_walk_time'] = transfer_stops['transfer_distance'] / WALKING_SPEED\n",
    "    transfer_stops = transfer_stops[['stop_id_x', 'stop_id_y', 'transfer_walk_time']]\n",
    "    return stops, transfer_stops\n",
    "\n",
    "def find_nearby_stops(stops):\n",
    "    t1 = time.time()\n",
    "    ## Returns a dataframe containing all pairs of stops that are within walking distance of each other\n",
    "    ## This function works by dividing the region into cells, each containing 0.1 degrees of longitude and latitude\n",
    "    ## Stops are paired if they are in the same or neighbouring cell (including diagonal neighbours)    \n",
    "    ## For Ireland, 0.1 degrees longitude is about 6.6 kms, while 0.1 degrees latitude is about 11.1 kms\n",
    "    ## So this function will identify every pair of stops that are less than 6.6 kms apart\n",
    "        \n",
    "    decimals = 1\n",
    "    round_precision = 0.1  # degrees longitude/latitude\n",
    "    middle = round_precision / 2\n",
    "    \n",
    "    rounded_stops = stops.copy()\n",
    "    \n",
    "    ## lat_ceil, lat_floor, lon_ceil, lon_floor are the lat/lon values of the four edges of the cell\n",
    "    rounded_stops['lat_ceil'] = rounded_stops['stop_lat'] + middle\n",
    "    rounded_stops['lat_ceil'] = rounded_stops['lat_ceil'].round(decimals)\n",
    "\n",
    "    rounded_stops['lon_ceil'] = rounded_stops['stop_lon'] + middle\n",
    "    rounded_stops['lon_ceil'] = rounded_stops['lon_ceil'].round(decimals)\n",
    "\n",
    "    rounded_stops['lat_floor'] = rounded_stops['lat_ceil'] - round_precision\n",
    "    rounded_stops['lon_floor'] = rounded_stops['lon_ceil'] - round_precision\n",
    "    \n",
    "        \n",
    "    cell_edges = []  \n",
    "    ## This list will contain 4 DataFrames, one for each of the four corners of the cells\n",
    "    ## These DataFrames will be concatenated into a single DataFrame\n",
    "    ## Each stop in this DataFrame will have 4 rows, indicating the locations of the 4 corners of its cell\n",
    "    ## By merging this DataFrame with itself, we will get every pair of stops that are in neighbouring cells    \n",
    "    \n",
    "    for lat_round in ['ceil', 'floor']:\n",
    "        for lon_round in ['ceil', 'floor']:\n",
    "            df = rounded_stops[['stop_id', 'lat_' + lat_round, 'lon_' + lon_round, 'stop_lat', 'stop_lon']]\n",
    "            df = df.rename(columns={'lat_' + lat_round: 'rounded_lat',\n",
    "                                    'lon_' + lon_round: 'rounded_lon'})\n",
    "            \n",
    "            cell_edges.append(df)    \n",
    "    \n",
    "    rounded_stops = pd.concat(cell_edges)    \n",
    "    rounded_stops_copy = rounded_stops.copy()\n",
    "    \n",
    "    nearby_stops = pd.merge(rounded_stops, rounded_stops_copy, on=['rounded_lat', 'rounded_lon'])\n",
    "    \n",
    "    nearby_stops = nearby_stops.drop_duplicates(['stop_id_x', 'stop_id_y']) # Stop pairs in cells with multiple shared vertices will appear multiple times\n",
    "    stop_x_coords = nearby_stops[['stop_lat_x', 'stop_lon_x']].values\n",
    "    stop_y_coords = nearby_stops[['stop_lat_y', 'stop_lon_y']].values\n",
    "\n",
    "    nearby_stops['transfer_distance'] = haversine_vector(stop_x_coords, stop_y_coords)\n",
    "\n",
    "    del stop_x_coords, stop_y_coords\n",
    "\n",
    "    nearby_stops = nearby_stops.sort_values('transfer_distance')\n",
    "    \n",
    "    return nearby_stops\n",
    "\n",
    "\n",
    "def find_nearby_stops2(stops):\n",
    "    t1 = time.time()\n",
    "    ## Returns a dataframe containing all pairs of stops that are within walking distance of each other\n",
    "    ## This function works by dividing the region into cells, each containing 0.1 degrees of longitude and latitude\n",
    "    ## Stops are paired if they are in the same or neighbouring cell (including diagonal neighbours)\n",
    "    ## For Ireland, 0.1 degrees longitude is about 6.6 kms, while 0.1 degrees latitude is about 11.1 kms\n",
    "    ## So this function will identify every pair of stops that are less than 6.6 kms apart\n",
    "        \n",
    "    decimals = 1\n",
    "    round_precision = 0.1  # degrees longitude/latitude\n",
    "    middle = round_precision / 2\n",
    "\n",
    "    rounded_stops = stops.copy()\n",
    "    \n",
    "    print(rounded_stops.columns)\n",
    "    ## lat_ceil, lat_floor, lon_ceil, lon_floor are the lat/lon values of the four edges of the cell\n",
    "    rounded_stops['lat_ceil'] = rounded_stops['stop_lat'] + middle\n",
    "    rounded_stops['lat_ceil'] = rounded_stops['lat_ceil'].round(decimals)\n",
    "\n",
    "    rounded_stops['lon_ceil'] = rounded_stops['stop_lon'] + middle\n",
    "    rounded_stops['lon_ceil'] = rounded_stops['lon_ceil'].round(decimals)\n",
    "\n",
    "    rounded_stops['lat_floor'] = rounded_stops['lat_ceil'] - round_precision\n",
    "    rounded_stops['lon_floor'] = rounded_stops['lon_ceil'] - round_precision\n",
    "\n",
    "    rounded_stops_copy = rounded_stops.copy()\n",
    "    \n",
    "    ## There are 9 cases to consider, corresponding to the 9 cells in a 3x3 grid where a nearby stop could be located\n",
    "    ## df1: both stops in same cell => (lat_ceil, lon_ceil)_x = (lat_ceil, lon_ceil)_y\n",
    "    ## df2a/b: cells are north/south neighbours => (lat_ceil, lon_ceil)_x = (lat_floor, lon_ceil)_y\n",
    "    ## df3a/b: cells are east/west neighbours => (lat_ceil, lon_ceil)_x = (lat_ceil, lon_floor)_y\n",
    "    ## df4a/b: cells are NE/SW diagonal neighbours => (lat_ceil, lon_ceil)_x = (lat_floor, lon_floor)_y\n",
    "    ## df5a/b: cells are NW/SE diagonal neighbours => (lat_ceil, lon_floor)_x = (lat_floor, lon_ceil)_y\n",
    "\n",
    "    \n",
    "    df1 = pd.merge(rounded_stops, rounded_stops_copy, left_on=['lat_ceil', 'lon_ceil'], right_on=['lat_ceil', 'lon_ceil'])\n",
    "    \n",
    "    df2a = pd.merge(rounded_stops, rounded_stops_copy, left_on=['lat_ceil', 'lon_ceil'], right_on=['lat_floor', 'lon_ceil'])\n",
    "    df2b = pd.merge(rounded_stops, rounded_stops_copy, left_on=['lat_floor', 'lon_ceil'], right_on=['lat_ceil', 'lon_ceil'])\n",
    "\n",
    "    df3a = pd.merge(rounded_stops, rounded_stops_copy, left_on=['lat_ceil', 'lon_ceil'], right_on=['lat_ceil', 'lon_floor'])\n",
    "    df3b = pd.merge(rounded_stops, rounded_stops_copy, left_on=['lat_ceil', 'lon_floor'], right_on=['lat_ceil', 'lon_ceil'])\n",
    "\n",
    "    df4a = pd.merge(rounded_stops, rounded_stops_copy, left_on=['lat_ceil', 'lon_ceil'], right_on=['lat_floor', 'lon_floor'])\n",
    "    df4b = pd.merge(rounded_stops, rounded_stops_copy, left_on=['lat_floor', 'lon_floor'], right_on=['lat_ceil', 'lon_ceil'])\n",
    "\n",
    "    df5a = pd.merge(rounded_stops, rounded_stops_copy, left_on=['lat_ceil', 'lon_floor'], right_on=['lat_floor', 'lon_ceil'])\n",
    "    df5b = pd.merge(rounded_stops, rounded_stops_copy, left_on=['lat_floor', 'lon_ceil'], right_on=['lat_ceil', 'lon_floor'])\n",
    "\n",
    "    dfs = [df1, df2a, df2b, df3a, df3b, df4a, df4b, df5a, df5b]\n",
    "\n",
    "    nearby_stops = pd.concat(dfs)\n",
    "\n",
    "    nearby_stops = nearby_stops[['stop_id_x', 'stop_lat_x', 'stop_lon_x', \n",
    "                                 'stop_id_y', 'stop_lat_y', 'stop_lon_y']]\n",
    "\n",
    "    del df1, df2a, df2b, df3a, df3b, df4a, df4b, df5a, df5b, dfs, rounded_stops, rounded_stops_copy\n",
    "    \n",
    "    stop_x_coords = nearby_stops[['stop_lat_x', 'stop_lon_x']].values\n",
    "    stop_y_coords = nearby_stops[['stop_lat_y', 'stop_lon_y']].values\n",
    "\n",
    "    nearby_stops['transfer_distance'] = haversine_vector(stop_x_coords, stop_y_coords)\n",
    "\n",
    "    del stop_x_coords, stop_y_coords\n",
    "\n",
    "    nearby_stops = nearby_stops.sort_values('transfer_distance')\n",
    "    return nearby_stops\n",
    "\n",
    "stops, transfer_stops = import_stops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id_x</th>\n",
       "      <th>stop_id_y</th>\n",
       "      <th>transfer_walk_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700000015422</td>\n",
       "      <td>700000015422</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25098649</th>\n",
       "      <td>8450B3314701</td>\n",
       "      <td>8450B3314701</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751312</th>\n",
       "      <td>8220DB000522</td>\n",
       "      <td>8220DB000522</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25098602</th>\n",
       "      <td>8450B3314601</td>\n",
       "      <td>8450B3314601</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25098555</th>\n",
       "      <td>8450B3314501</td>\n",
       "      <td>8450B3314501</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10665097</th>\n",
       "      <td>8260B1038901</td>\n",
       "      <td>826000094</td>\n",
       "      <td>0.399998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25051754</th>\n",
       "      <td>8440B352541</td>\n",
       "      <td>844000056</td>\n",
       "      <td>0.399999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25078034</th>\n",
       "      <td>844000056</td>\n",
       "      <td>8440B352541</td>\n",
       "      <td>0.399999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175132</th>\n",
       "      <td>8220B123501</td>\n",
       "      <td>8220DB001515</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361032</th>\n",
       "      <td>8220DB001515</td>\n",
       "      <td>8220B123501</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012794 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             stop_id_x     stop_id_y  transfer_walk_time\n",
       "0         700000015422  700000015422            0.000000\n",
       "25098649  8450B3314701  8450B3314701            0.000000\n",
       "751312    8220DB000522  8220DB000522            0.000000\n",
       "25098602  8450B3314601  8450B3314601            0.000000\n",
       "25098555  8450B3314501  8450B3314501            0.000000\n",
       "...                ...           ...                 ...\n",
       "10665097  8260B1038901     826000094            0.399998\n",
       "25051754   8440B352541     844000056            0.399999\n",
       "25078034     844000056   8440B352541            0.399999\n",
       "175132     8220B123501  8220DB001515            0.400000\n",
       "1361032   8220DB001515   8220B123501            0.400000\n",
       "\n",
       "[1012794 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1b: import vaccine centre location data and identify nearby stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>merge_key</th>\n",
       "      <th>Facility Latitude</th>\n",
       "      <th>Facility Longitude</th>\n",
       "      <th>County</th>\n",
       "      <th>Facility</th>\n",
       "      <th>Address</th>\n",
       "      <th>stop_to_vax_hub_distance</th>\n",
       "      <th>stop_to_vax_hub_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266744</th>\n",
       "      <td>8220DB007571</td>\n",
       "      <td>DCU Helix, stop 7571</td>\n",
       "      <td>53.386776</td>\n",
       "      <td>-6.258725</td>\n",
       "      <td>1</td>\n",
       "      <td>53.386560</td>\n",
       "      <td>-6.259032</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>Helix Theatre DCU</td>\n",
       "      <td>DCU Santry</td>\n",
       "      <td>0.031458</td>\n",
       "      <td>0.006292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79073</th>\n",
       "      <td>8370B2368501</td>\n",
       "      <td>Eglinton Street, stop 236851</td>\n",
       "      <td>51.897310</td>\n",
       "      <td>-8.464863</td>\n",
       "      <td>1</td>\n",
       "      <td>51.897136</td>\n",
       "      <td>-8.465482</td>\n",
       "      <td>Cork</td>\n",
       "      <td>City Hall Cork</td>\n",
       "      <td>City Hall, Anglesea Street, Cork city</td>\n",
       "      <td>0.046698</td>\n",
       "      <td>0.009340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74483</th>\n",
       "      <td>8360B603331</td>\n",
       "      <td>West County Hotel, stop 603331</td>\n",
       "      <td>52.831752</td>\n",
       "      <td>-8.980457</td>\n",
       "      <td>1</td>\n",
       "      <td>52.831327</td>\n",
       "      <td>-8.980353</td>\n",
       "      <td>Clare</td>\n",
       "      <td>West County Hotel</td>\n",
       "      <td>Limerick Road, Ennis</td>\n",
       "      <td>0.047821</td>\n",
       "      <td>0.009564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410200</th>\n",
       "      <td>828000017</td>\n",
       "      <td>Old Post Office Portlaoise</td>\n",
       "      <td>53.034486</td>\n",
       "      <td>-7.302756</td>\n",
       "      <td>1</td>\n",
       "      <td>53.035026</td>\n",
       "      <td>-7.302458</td>\n",
       "      <td>Laois</td>\n",
       "      <td>Midlands Park Hotel</td>\n",
       "      <td>Jessop St., Portlaoise, Co Laois</td>\n",
       "      <td>0.063307</td>\n",
       "      <td>0.012661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410163</th>\n",
       "      <td>828000016</td>\n",
       "      <td>Old Post Office Portlaoise</td>\n",
       "      <td>53.034460</td>\n",
       "      <td>-7.302905</td>\n",
       "      <td>1</td>\n",
       "      <td>53.035026</td>\n",
       "      <td>-7.302458</td>\n",
       "      <td>Laois</td>\n",
       "      <td>Midlands Park Hotel</td>\n",
       "      <td>Jessop St., Portlaoise, Co Laois</td>\n",
       "      <td>0.069738</td>\n",
       "      <td>0.013948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161935</th>\n",
       "      <td>8470B5304301</td>\n",
       "      <td>Ballyconneely, stop 530431</td>\n",
       "      <td>53.431157</td>\n",
       "      <td>-10.075430</td>\n",
       "      <td>1</td>\n",
       "      <td>53.843820</td>\n",
       "      <td>-9.239317</td>\n",
       "      <td>Mayo</td>\n",
       "      <td>Breaffy House Resort</td>\n",
       "      <td>Breaffy, Castlebar, Co Mayo</td>\n",
       "      <td>71.720747</td>\n",
       "      <td>14.344149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359921</th>\n",
       "      <td>700000014719</td>\n",
       "      <td>Belfast City Centre, Glengall Street</td>\n",
       "      <td>54.595088</td>\n",
       "      <td>-5.937195</td>\n",
       "      <td>1</td>\n",
       "      <td>53.967790</td>\n",
       "      <td>-6.387424</td>\n",
       "      <td>Louth</td>\n",
       "      <td>Fairways Hotel</td>\n",
       "      <td>Dublin Rd, Haggardstown, Dundalk, Co Louth</td>\n",
       "      <td>75.627856</td>\n",
       "      <td>15.125571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>700000015422</td>\n",
       "      <td>Belfast, Europa Bus Centre</td>\n",
       "      <td>54.595054</td>\n",
       "      <td>-5.936268</td>\n",
       "      <td>1</td>\n",
       "      <td>53.967790</td>\n",
       "      <td>-6.387424</td>\n",
       "      <td>Louth</td>\n",
       "      <td>Fairways Hotel</td>\n",
       "      <td>Dublin Rd, Haggardstown, Dundalk, Co Louth</td>\n",
       "      <td>75.647670</td>\n",
       "      <td>15.129534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456750</th>\n",
       "      <td>gen:31400:8239:0:1</td>\n",
       "      <td>Belfast City Centre, Jury's Inn</td>\n",
       "      <td>54.596260</td>\n",
       "      <td>-5.934783</td>\n",
       "      <td>1</td>\n",
       "      <td>53.967790</td>\n",
       "      <td>-6.387424</td>\n",
       "      <td>Louth</td>\n",
       "      <td>Fairways Hotel</td>\n",
       "      <td>Dublin Rd, Haggardstown, Dundalk, Co Louth</td>\n",
       "      <td>75.808460</td>\n",
       "      <td>15.161692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399030</th>\n",
       "      <td>g:31400:11</td>\n",
       "      <td>Belfast City Centre, Lanyon Place</td>\n",
       "      <td>54.595530</td>\n",
       "      <td>-5.917331</td>\n",
       "      <td>1</td>\n",
       "      <td>53.967790</td>\n",
       "      <td>-6.387424</td>\n",
       "      <td>Louth</td>\n",
       "      <td>Fairways Hotel</td>\n",
       "      <td>Dublin Rd, Haggardstown, Dundalk, Co Louth</td>\n",
       "      <td>76.180376</td>\n",
       "      <td>15.236075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12614 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   stop_id                             stop_name   stop_lat  \\\n",
       "266744        8220DB007571                  DCU Helix, stop 7571  53.386776   \n",
       "79073         8370B2368501          Eglinton Street, stop 236851  51.897310   \n",
       "74483          8360B603331        West County Hotel, stop 603331  52.831752   \n",
       "410200           828000017            Old Post Office Portlaoise  53.034486   \n",
       "410163           828000016            Old Post Office Portlaoise  53.034460   \n",
       "...                    ...                                   ...        ...   \n",
       "161935        8470B5304301            Ballyconneely, stop 530431  53.431157   \n",
       "359921        700000014719  Belfast City Centre, Glengall Street  54.595088   \n",
       "22            700000015422            Belfast, Europa Bus Centre  54.595054   \n",
       "456750  gen:31400:8239:0:1       Belfast City Centre, Jury's Inn  54.596260   \n",
       "399030          g:31400:11     Belfast City Centre, Lanyon Place  54.595530   \n",
       "\n",
       "         stop_lon  merge_key  Facility Latitude  Facility Longitude  County  \\\n",
       "266744  -6.258725          1          53.386560           -6.259032  Dublin   \n",
       "79073   -8.464863          1          51.897136           -8.465482    Cork   \n",
       "74483   -8.980457          1          52.831327           -8.980353   Clare   \n",
       "410200  -7.302756          1          53.035026           -7.302458   Laois   \n",
       "410163  -7.302905          1          53.035026           -7.302458   Laois   \n",
       "...           ...        ...                ...                 ...     ...   \n",
       "161935 -10.075430          1          53.843820           -9.239317    Mayo   \n",
       "359921  -5.937195          1          53.967790           -6.387424   Louth   \n",
       "22      -5.936268          1          53.967790           -6.387424   Louth   \n",
       "456750  -5.934783          1          53.967790           -6.387424   Louth   \n",
       "399030  -5.917331          1          53.967790           -6.387424   Louth   \n",
       "\n",
       "                    Facility                                     Address  \\\n",
       "266744     Helix Theatre DCU                                  DCU Santry   \n",
       "79073         City Hall Cork       City Hall, Anglesea Street, Cork city   \n",
       "74483      West County Hotel                        Limerick Road, Ennis   \n",
       "410200   Midlands Park Hotel            Jessop St., Portlaoise, Co Laois   \n",
       "410163   Midlands Park Hotel            Jessop St., Portlaoise, Co Laois   \n",
       "...                      ...                                         ...   \n",
       "161935  Breaffy House Resort                 Breaffy, Castlebar, Co Mayo   \n",
       "359921        Fairways Hotel  Dublin Rd, Haggardstown, Dundalk, Co Louth   \n",
       "22            Fairways Hotel  Dublin Rd, Haggardstown, Dundalk, Co Louth   \n",
       "456750        Fairways Hotel  Dublin Rd, Haggardstown, Dundalk, Co Louth   \n",
       "399030        Fairways Hotel  Dublin Rd, Haggardstown, Dundalk, Co Louth   \n",
       "\n",
       "        stop_to_vax_hub_distance  stop_to_vax_hub_time  \n",
       "266744                  0.031458              0.006292  \n",
       "79073                   0.046698              0.009340  \n",
       "74483                   0.047821              0.009564  \n",
       "410200                  0.063307              0.012661  \n",
       "410163                  0.069738              0.013948  \n",
       "...                          ...                   ...  \n",
       "161935                 71.720747             14.344149  \n",
       "359921                 75.627856             15.125571  \n",
       "22                     75.647670             15.129534  \n",
       "456750                 75.808460             15.161692  \n",
       "399030                 76.180376             15.236075  \n",
       "\n",
       "[12614 rows x 12 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vax_hubs = pd.read_csv('Vaccine_Hubs.txt')\n",
    "vax_hubs['merge_key'] = 1\n",
    "\n",
    "vax_hub_stops = pd.merge(stops, vax_hubs, on='merge_key')\n",
    "stop_coords = vax_hub_stops[['stop_lat', 'stop_lon']].values\n",
    "vax_hub_coords = vax_hub_stops[['Facility Latitude', 'Facility Longitude']].values\n",
    "\n",
    "vax_hub_stops['stop_to_vax_hub_distance'] = haversine_vector(stop_coords, vax_hub_coords)\n",
    "vax_hub_stops['stop_to_vax_hub_time'] = vax_hub_stops['stop_to_vax_hub_distance'] / WALKING_SPEED\n",
    "vax_hub_stops = vax_hub_stops.sort_values('stop_to_vax_hub_distance')\n",
    "vax_hub_stops = vax_hub_stops.drop_duplicates('stop_id')\n",
    "vax_hub_stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1c: import data about trip times from the GTFS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trip stops = 6142633\n",
      "Number of trips = 128090\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>stop_headsign</th>\n",
       "      <th>pickup_type</th>\n",
       "      <th>drop_off_type</th>\n",
       "      <th>shape_dist_traveled</th>\n",
       "      <th>operator_x</th>\n",
       "      <th>...</th>\n",
       "      <th>monday</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>thursday</th>\n",
       "      <th>friday</th>\n",
       "      <th>saturday</th>\n",
       "      <th>sunday</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>operator_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.daily.1-700-y11-2.1.I</td>\n",
       "      <td>0 days 01:25:00</td>\n",
       "      <td>0 days 01:25:00</td>\n",
       "      <td>8240000548</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>google_transit_aircoach</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20201221</td>\n",
       "      <td>20211221</td>\n",
       "      <td>google_transit_aircoach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.daily.1-700-y11-2.1.I</td>\n",
       "      <td>0 days 01:45:00</td>\n",
       "      <td>0 days 01:45:00</td>\n",
       "      <td>8220DB000047</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9651.30</td>\n",
       "      <td>google_transit_aircoach</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20201221</td>\n",
       "      <td>20211221</td>\n",
       "      <td>google_transit_aircoach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.daily.1-700-y11-2.1.I</td>\n",
       "      <td>0 days 01:55:00</td>\n",
       "      <td>0 days 01:55:00</td>\n",
       "      <td>8220DB000272</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11379.45</td>\n",
       "      <td>google_transit_aircoach</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20201221</td>\n",
       "      <td>20211221</td>\n",
       "      <td>google_transit_aircoach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.daily.1-700-y11-2.1.I</td>\n",
       "      <td>0 days 01:58:00</td>\n",
       "      <td>0 days 01:58:00</td>\n",
       "      <td>8220DB000273</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11867.14</td>\n",
       "      <td>google_transit_aircoach</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20201221</td>\n",
       "      <td>20211221</td>\n",
       "      <td>google_transit_aircoach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.daily.1-700-y11-2.1.I</td>\n",
       "      <td>0 days 02:00:00</td>\n",
       "      <td>0 days 02:00:00</td>\n",
       "      <td>8220DB004530</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12957.82</td>\n",
       "      <td>google_transit_aircoach</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20201221</td>\n",
       "      <td>20211221</td>\n",
       "      <td>google_transit_aircoach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936421</th>\n",
       "      <td>13.MF-BH.14-WX2-y11-3.9.O</td>\n",
       "      <td>0 days 15:29:00</td>\n",
       "      <td>0 days 15:29:00</td>\n",
       "      <td>834000047</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9012.02</td>\n",
       "      <td>google_transit_wexfordbus</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210104</td>\n",
       "      <td>20220104</td>\n",
       "      <td>google_transit_wexfordbus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936422</th>\n",
       "      <td>13.MF-BH.14-WX2-y11-3.9.O</td>\n",
       "      <td>0 days 15:30:00</td>\n",
       "      <td>0 days 15:30:00</td>\n",
       "      <td>8340B3316201</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9289.60</td>\n",
       "      <td>google_transit_wexfordbus</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210104</td>\n",
       "      <td>20220104</td>\n",
       "      <td>google_transit_wexfordbus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936423</th>\n",
       "      <td>13.MF-BH.14-WX2-y11-3.9.O</td>\n",
       "      <td>0 days 15:31:00</td>\n",
       "      <td>0 days 15:31:00</td>\n",
       "      <td>834LL10364</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9739.56</td>\n",
       "      <td>google_transit_wexfordbus</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210104</td>\n",
       "      <td>20220104</td>\n",
       "      <td>google_transit_wexfordbus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936424</th>\n",
       "      <td>13.MF-BH.14-WX2-y11-3.9.O</td>\n",
       "      <td>0 days 15:32:00</td>\n",
       "      <td>0 days 15:32:00</td>\n",
       "      <td>834000055</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9957.11</td>\n",
       "      <td>google_transit_wexfordbus</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210104</td>\n",
       "      <td>20220104</td>\n",
       "      <td>google_transit_wexfordbus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936425</th>\n",
       "      <td>13.MF-BH.14-WX2-y11-3.9.O</td>\n",
       "      <td>0 days 15:33:00</td>\n",
       "      <td>0 days 15:33:00</td>\n",
       "      <td>8340LL10365</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10481.40</td>\n",
       "      <td>google_transit_wexfordbus</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20210104</td>\n",
       "      <td>20220104</td>\n",
       "      <td>google_transit_wexfordbus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3936426 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           trip_id    arrival_time  departure_time  \\\n",
       "0          9.daily.1-700-y11-2.1.I 0 days 01:25:00 0 days 01:25:00   \n",
       "1          9.daily.1-700-y11-2.1.I 0 days 01:45:00 0 days 01:45:00   \n",
       "2          9.daily.1-700-y11-2.1.I 0 days 01:55:00 0 days 01:55:00   \n",
       "3          9.daily.1-700-y11-2.1.I 0 days 01:58:00 0 days 01:58:00   \n",
       "4          9.daily.1-700-y11-2.1.I 0 days 02:00:00 0 days 02:00:00   \n",
       "...                            ...             ...             ...   \n",
       "3936421  13.MF-BH.14-WX2-y11-3.9.O 0 days 15:29:00 0 days 15:29:00   \n",
       "3936422  13.MF-BH.14-WX2-y11-3.9.O 0 days 15:30:00 0 days 15:30:00   \n",
       "3936423  13.MF-BH.14-WX2-y11-3.9.O 0 days 15:31:00 0 days 15:31:00   \n",
       "3936424  13.MF-BH.14-WX2-y11-3.9.O 0 days 15:32:00 0 days 15:32:00   \n",
       "3936425  13.MF-BH.14-WX2-y11-3.9.O 0 days 15:33:00 0 days 15:33:00   \n",
       "\n",
       "              stop_id  stop_sequence stop_headsign  pickup_type  \\\n",
       "0          8240000548              1           NaN          0.0   \n",
       "1        8220DB000047              2           NaN          1.0   \n",
       "2        8220DB000272              3           NaN          1.0   \n",
       "3        8220DB000273              4           NaN          1.0   \n",
       "4        8220DB004530              5           NaN          1.0   \n",
       "...               ...            ...           ...          ...   \n",
       "3936421     834000047             21           NaN          0.0   \n",
       "3936422  8340B3316201             22           NaN          0.0   \n",
       "3936423    834LL10364             23           NaN          0.0   \n",
       "3936424     834000055             24           NaN          0.0   \n",
       "3936425   8340LL10365             25           NaN          0.0   \n",
       "\n",
       "         drop_off_type  shape_dist_traveled                 operator_x  ...  \\\n",
       "0                  1.0                 0.00    google_transit_aircoach  ...   \n",
       "1                  0.0              9651.30    google_transit_aircoach  ...   \n",
       "2                  0.0             11379.45    google_transit_aircoach  ...   \n",
       "3                  0.0             11867.14    google_transit_aircoach  ...   \n",
       "4                  0.0             12957.82    google_transit_aircoach  ...   \n",
       "...                ...                  ...                        ...  ...   \n",
       "3936421            0.0              9012.02  google_transit_wexfordbus  ...   \n",
       "3936422            0.0              9289.60  google_transit_wexfordbus  ...   \n",
       "3936423            0.0              9739.56  google_transit_wexfordbus  ...   \n",
       "3936424            0.0              9957.11  google_transit_wexfordbus  ...   \n",
       "3936425            0.0             10481.40  google_transit_wexfordbus  ...   \n",
       "\n",
       "         monday  tuesday wednesday thursday friday saturday  sunday  \\\n",
       "0             1        1         1        1      1        1       1   \n",
       "1             1        1         1        1      1        1       1   \n",
       "2             1        1         1        1      1        1       1   \n",
       "3             1        1         1        1      1        1       1   \n",
       "4             1        1         1        1      1        1       1   \n",
       "...         ...      ...       ...      ...    ...      ...     ...   \n",
       "3936421       1        1         1        1      1        0       0   \n",
       "3936422       1        1         1        1      1        0       0   \n",
       "3936423       1        1         1        1      1        0       0   \n",
       "3936424       1        1         1        1      1        0       0   \n",
       "3936425       1        1         1        1      1        0       0   \n",
       "\n",
       "         start_date  end_date                 operator_y  \n",
       "0          20201221  20211221    google_transit_aircoach  \n",
       "1          20201221  20211221    google_transit_aircoach  \n",
       "2          20201221  20211221    google_transit_aircoach  \n",
       "3          20201221  20211221    google_transit_aircoach  \n",
       "4          20201221  20211221    google_transit_aircoach  \n",
       "...             ...       ...                        ...  \n",
       "3936421    20210104  20220104  google_transit_wexfordbus  \n",
       "3936422    20210104  20220104  google_transit_wexfordbus  \n",
       "3936423    20210104  20220104  google_transit_wexfordbus  \n",
       "3936424    20210104  20220104  google_transit_wexfordbus  \n",
       "3936425    20210104  20220104  google_transit_wexfordbus  \n",
       "\n",
       "[3936426 rows x 27 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def import_stop_times():\n",
    "    stop_times_dfs = []\n",
    "    \n",
    "    for operator in operators:\n",
    "        stop_times = pd.read_csv(gtfs_folder + '\\\\' + operator + '\\\\' + 'stop_times.txt')\n",
    "        stop_times['operator'] = operator\n",
    "        stop_times_dfs.append(stop_times)\n",
    "    \n",
    "    stop_times = pd.concat(stop_times_dfs)\n",
    "    stop_times['departure_time'] = pd.to_timedelta(stop_times['departure_time'])\n",
    "    stop_times['arrival_time'] = pd.to_timedelta(stop_times['arrival_time'])\n",
    "    \n",
    "    stop_times['departure_time_hrs'] = stop_times['departure_time'].dt.total_seconds() / (60 * 60)\n",
    "    stop_times['arrival_time_hrs'] = stop_times['arrival_time'].dt.total_seconds() / (60 * 60)\n",
    "\n",
    "    stop_times = stop_times.drop_duplicates(['trip_id', 'stop_sequence'])\n",
    "    print(\"Number of trip stops =\", len(stop_times.index))\n",
    "    return stop_times\n",
    "\n",
    "def import_trip_data():\n",
    "    trip_dfs = []\n",
    "    todays_date = 20210225\n",
    "    \n",
    "    for operator in operators:\n",
    "        calendar = pd.read_csv(gtfs_folder + '\\\\' + operator + '\\\\' + 'calendar.txt')\n",
    "        calendar = calendar[(calendar['end_date'] > todays_date) & \n",
    "                            (calendar['start_date'] < todays_date)]\n",
    "        \n",
    "        trips = pd.read_csv(gtfs_folder + '\\\\' + operator + '\\\\' + 'trips.txt')\n",
    "        trips = pd.merge(trips, calendar, on='service_id')\n",
    "        trips['operator'] = operator\n",
    "        trip_dfs.append(trips)\n",
    "    \n",
    "    trips = pd.concat(trip_dfs)\n",
    "\n",
    "    del calendar, trip_dfs\n",
    "\n",
    "    print(\"Number of trips =\", len(trips.index))    \n",
    "    return trips\n",
    "\n",
    "stop_times = import_stop_times()\n",
    "trip_data = import_trip_data()\n",
    "stop_times = pd.merge(stop_times, trip_data, on='trip_id')\n",
    "stop_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1d: Select a day of the week for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>pickup_type</th>\n",
       "      <th>drop_off_type</th>\n",
       "      <th>departure_time_hrs</th>\n",
       "      <th>arrival_time_hrs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>35.daily.1-700-y11-2.1.I</td>\n",
       "      <td>8240000548</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.416667</td>\n",
       "      <td>19.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>35.daily.1-700-y11-2.1.I</td>\n",
       "      <td>8220DB000047</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.750000</td>\n",
       "      <td>19.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>35.daily.1-700-y11-2.1.I</td>\n",
       "      <td>8220DB000272</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.916667</td>\n",
       "      <td>19.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>35.daily.1-700-y11-2.1.I</td>\n",
       "      <td>8220DB000273</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.966667</td>\n",
       "      <td>19.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>35.daily.1-700-y11-2.1.I</td>\n",
       "      <td>8220DB004530</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779185</th>\n",
       "      <td>1340.TA.99-13-r11-1.11.O</td>\n",
       "      <td>822GIR0141</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.966667</td>\n",
       "      <td>19.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779186</th>\n",
       "      <td>1340.TA.99-13-r11-1.11.O</td>\n",
       "      <td>824G003874</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.983333</td>\n",
       "      <td>19.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779187</th>\n",
       "      <td>1340.TA.99-13-r11-1.11.O</td>\n",
       "      <td>824GIR0140</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.033333</td>\n",
       "      <td>20.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779188</th>\n",
       "      <td>1340.TA.99-13-r11-1.11.O</td>\n",
       "      <td>824GIR0024</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.066667</td>\n",
       "      <td>20.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779189</th>\n",
       "      <td>1340.TA.99-13-r11-1.11.O</td>\n",
       "      <td>824GIR0017</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.150000</td>\n",
       "      <td>20.150000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411656 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          trip_id       stop_id  stop_sequence  pickup_type  \\\n",
       "66       35.daily.1-700-y11-2.1.I    8240000548              1          0.0   \n",
       "67       35.daily.1-700-y11-2.1.I  8220DB000047              2          1.0   \n",
       "68       35.daily.1-700-y11-2.1.I  8220DB000272              3          1.0   \n",
       "69       35.daily.1-700-y11-2.1.I  8220DB000273              4          1.0   \n",
       "70       35.daily.1-700-y11-2.1.I  8220DB004530              5          1.0   \n",
       "...                           ...           ...            ...          ...   \n",
       "3779185  1340.TA.99-13-r11-1.11.O    822GIR0141             23          0.0   \n",
       "3779186  1340.TA.99-13-r11-1.11.O    824G003874             24          0.0   \n",
       "3779187  1340.TA.99-13-r11-1.11.O    824GIR0140             25          0.0   \n",
       "3779188  1340.TA.99-13-r11-1.11.O    824GIR0024             26          0.0   \n",
       "3779189  1340.TA.99-13-r11-1.11.O    824GIR0017             27          0.0   \n",
       "\n",
       "         drop_off_type  departure_time_hrs  arrival_time_hrs  \n",
       "66                 1.0           19.416667         19.416667  \n",
       "67                 0.0           19.750000         19.750000  \n",
       "68                 0.0           19.916667         19.916667  \n",
       "69                 0.0           19.966667         19.966667  \n",
       "70                 0.0           20.000000         20.000000  \n",
       "...                ...                 ...               ...  \n",
       "3779185            0.0           19.966667         19.950000  \n",
       "3779186            0.0           19.983333         19.983333  \n",
       "3779187            0.0           20.033333         20.016667  \n",
       "3779188            0.0           20.066667         20.050000  \n",
       "3779189            0.0           20.150000         20.150000  \n",
       "\n",
       "[411656 rows x 7 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliest_departure = 13\n",
    "latest_arrival = 23\n",
    "\n",
    "days = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "day_index = 5 # Saturday\n",
    "day = days[day_index]\n",
    "prev_day = days[(day_index-1) % 7]\n",
    "\n",
    "daytime_stop_times = stop_times[(stop_times.departure_time_hrs > earliest_departure) &\n",
    "                                (stop_times.arrival_time_hrs < latest_arrival)]\n",
    "daytime_stop_times = daytime_stop_times[daytime_stop_times[day] == 1]\n",
    "\n",
    "## We also need to account for trips where the dep/arr times are over 24 hours\n",
    "prev_daytime_stop_times = stop_times[(stop_times.departure_time_hrs > 24 + earliest_departure) &\n",
    "                                     (stop_times.arrival_time_hrs < 24 + latest_arrival)]\n",
    "prev_daytime_stop_times = prev_daytime_stop_times[prev_daytime_stop_times[prev_day] == 1]\n",
    "prev_daytime_stop_times['departure_time_hrs'] -= 24\n",
    "prev_daytime_stop_times['arrival_time_hrs'] -= 24\n",
    "\n",
    "daytime_stop_times = pd.concat([daytime_stop_times, prev_daytime_stop_times])\n",
    "daytime_stop_times = daytime_stop_times[['trip_id', 'stop_id', 'stop_sequence', 'pickup_type',\n",
    "                                         'drop_off_type', 'departure_time_hrs', 'arrival_time_hrs']]\n",
    "\n",
    "arrivals = daytime_stop_times[daytime_stop_times['drop_off_type']==0][['trip_id', 'stop_id', 'stop_sequence', 'arrival_time_hrs']]\n",
    "departures = daytime_stop_times[daytime_stop_times['pickup_type']==0][['trip_id', 'stop_id', 'stop_sequence', 'departure_time_hrs']]\n",
    "\n",
    "daytime_stop_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: the routing algorithm\n",
    "\n",
    "Next we need to find the journey time to every transit stop from a vaccine centre.\n",
    "\n",
    "The algorithm used here is a breadth first search, where all possible trips are saved unless they are proven to be suboptimal.\n",
    "\n",
    "### What is a sub-optimal trip?\n",
    "\n",
    "In this case, a trip is sub-optimal if there is another trip which leaves a vaccine centre later and arrives at the same stop earlier.\n",
    "\n",
    "There are two important caveats to note:\n",
    "\n",
    "Firstly, the departure time used is adjusted to account for aversion to large amounts of walking. The formula is:\n",
    "\n",
    "    adj_journey_dep_time = journey_dep_time - WALK_EFFORT_FACTOR * total_walk_time\n",
    "\n",
    "where WALK_EFFORT_FACTOR is a number which increases with aversion to walking. Effectively, this gives a slight preference to longer journeys with less walking.\n",
    "\n",
    "A second adjustment is also made to trips that are exclusively on foot. This adjustment reflects the fact that people are unlikely to take a public transport journey for a trip that can be walked in a comparable amount of time, even if the public transport option is a little faster. For this algorithm, a public transport option would only be chosen over walking if it is at least 5 minutes faster end to end. This eliminates hyperlocal transit journeys.\n",
    "\n",
    "### How are the trips stored?\n",
    "\n",
    "The trips are saved in a DataFrame, with each row representing a single trip. The columns of the DataFrame tell us the important information about the trip such as the departure and arrival times, the vaccination centre used, the amount of walking, and the trip_ids and stop_ids along the way.\n",
    "\n",
    "The columns in the DataFrame are as follows:\n",
    "\n",
    "1. departure_facility\n",
    "2. total_walk_time: includes all time spent walking at the start and at transfers, but not waiting time at transfers\n",
    "3. journey_dep_time: This is the time of departure from the vaccination centre\n",
    "4. journey_arrival_time: This is the time of arrival in the final stop\n",
    "5. adj_journey_dep_time: This is the adjusted departure time, accounting for aversion to walking, and used to identify sub-optimal trips\n",
    "6. final_stop_id\n",
    "7. walk_1_time: Time to walk from the vaccination centre to the first stop\n",
    "8. stop_1a_id: First departure stop\n",
    "9. trip_1_id\n",
    "10. trip_1_departure_time\n",
    "11. trip_1_arrival_time\n",
    "12. stop_1b_id: First arrival stop\n",
    "\n",
    "Columns 1-6 relate to the overall journey\n",
    "\n",
    "Columns 7-12 give the details of the first leg\n",
    "\n",
    "Each subsequent leg of the journey will use the same format as columns 7-12, but with a different number.\n",
    "\n",
    "Note that walk_2_time, walk_3_time, etc only measure the actual walk time, not the total time from arriving in one stop to departing from the next.\n",
    "\n",
    "### How are sub-optimal trips identified?\n",
    "\n",
    "Given a DataFrame as described above, how do we identify and remove the rows coresponding to sub-optimal trips?\n",
    "\n",
    "Walkable trips can be identified by merging the DataFrame with vax_hub_stops on final_stop_id. From here, we can easily compare the trip time with the journey time on foot for each row, keeping only rows where the transit journey time is at least 5 minutes faster.\n",
    "\n",
    "For late depart/early arrive, the algorithm is a little more involved. The solution used here starts by sorting the DataFrame by final_stop_id and journey_arrival_time. This ensures that all rows with the same final_stop_id are clustered together, with arrival times increasing. The first occurence of every final_stop_id is retained, since this corresponds to the earliest known arrival. Other rows are retained only if their adjusted departure time is later than the adjusted departure time for the previous row.\n",
    "\n",
    "##### Sub-optimal departures\n",
    "Throughout this algorithm, there will be several times when the trips are only partially computed. One case is when the possible departures have been identified, but not the corresponding arrivals. It is very important to note that the late depart/early arrive process cannot be used in this situation, since it is not sub-optimal to skip a departure to catch a bus to a different place. However, there is a variant of this algorithm which does work in this situation:\n",
    "\n",
    "Under this process, a trip can be identified as sub-optimal if there is another trip which departs the vaccination centre later and joins the same bus/train journey earlier in the vehicle's journey. This process is extremely useful for managing transit routes which run alongside one another. The problem here is that without this check, a tranfer between parallel bus routes will be replicated at every stop along the parallel section. In Dublin, this can easily be dozens of stops with an effectively identical transfer. This process reduces all of those down to one.\n",
    "\n",
    "### Bringing it all together\n",
    "\n",
    "The process for the full algorithm is as follows:\n",
    "#### 1. Find stops within walking distance of a given vaccination centre\n",
    "    This information can be pulled from vax_hub_stops, by filtering stop_to_vax_hub_distance\n",
    "    For this analysis, the maximum walking distance is set to 5 kms\n",
    "    There are three columns we need to retain: departure_facility, stop_id and stop_to_vax_hub_time\n",
    "#### 2. Find all departures from those stops\n",
    "    We do this by merging the DataFrame from the previous step with the departures DataFrame on the stop_id column\n",
    "    This will give us a DataFrame containing the first 10 columns from above\n",
    "#### 3. Find arrivals corresponding to those departures\n",
    "    The next step is to merge the DataFrame with the arrivals DataFrame, using the trip_id as the merge key\n",
    "    We need to do a further check to ensure the arrival stop occurs after the departure stop. Conveniently, the stops are\n",
    "    numbered for each trip, so we simply need to keep the rows where the arrival stop number is bigger than the departure \n",
    "    stop number.\n",
    "    We now have all 12 columns corresponding to a single trip journey\n",
    "#### 4. Remove sub-optimal trips\n",
    "    We use the processes described above to remove sub-optimal rows\n",
    "#### 5. Find transfer stops and remove sub-optimal trips\n",
    "    This involves merging the DataFrame with transfer_stops on final_stop_id.\n",
    "    Some trips will become sub-optimal due to the presence of a superior trip at a nearby stop.\n",
    "#### 6. Identify departures, as in step 2 and remove sub-optimal departures\n",
    "    Note that this merge gets very conputationally intenstive, and is immediately followed by a significant optimisation, as discussed above.\n",
    "    Therefore, it is generally faster to perform the merge and optimisation in chunks.\n",
    "#### 7. Identify arrivals as in step 3 and remove sub-optimal trips \n",
    "#### 8. Repeat steps 5-7 for each subsequent leg   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rural stops:  2950\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id_x</th>\n",
       "      <th>stop_id_y</th>\n",
       "      <th>transfer_walk_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700000015422</td>\n",
       "      <td>700000015422</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25098649</th>\n",
       "      <td>8450B3314701</td>\n",
       "      <td>8450B3314701</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751312</th>\n",
       "      <td>8220DB000522</td>\n",
       "      <td>8220DB000522</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25098602</th>\n",
       "      <td>8450B3314601</td>\n",
       "      <td>8450B3314601</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25098555</th>\n",
       "      <td>8450B3314501</td>\n",
       "      <td>8450B3314501</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10851212</th>\n",
       "      <td>8470PB000860</td>\n",
       "      <td>8470PB000857</td>\n",
       "      <td>0.398976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23059782</th>\n",
       "      <td>8360B336431</td>\n",
       "      <td>836GIR0003</td>\n",
       "      <td>0.399008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23062190</th>\n",
       "      <td>836GIR0003</td>\n",
       "      <td>8360B336431</td>\n",
       "      <td>0.399008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25951363</th>\n",
       "      <td>853000334</td>\n",
       "      <td>853000120</td>\n",
       "      <td>0.399749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25951354</th>\n",
       "      <td>853000120</td>\n",
       "      <td>853000334</td>\n",
       "      <td>0.399749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>330132 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             stop_id_x     stop_id_y  transfer_walk_time\n",
       "0         700000015422  700000015422            0.000000\n",
       "25098649  8450B3314701  8450B3314701            0.000000\n",
       "751312    8220DB000522  8220DB000522            0.000000\n",
       "25098602  8450B3314601  8450B3314601            0.000000\n",
       "25098555  8450B3314501  8450B3314501            0.000000\n",
       "...                ...           ...                 ...\n",
       "10851212  8470PB000860  8470PB000857            0.398976\n",
       "23059782   8360B336431    836GIR0003            0.399008\n",
       "23062190    836GIR0003   8360B336431            0.399008\n",
       "25951363     853000334     853000120            0.399749\n",
       "25951354     853000120     853000334            0.399749\n",
       "\n",
       "[330132 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc = transfer_stops['stop_id_x'].value_counts()\n",
    "rural_stops = vc[vc < 5].index\n",
    "print(\"Number of rural stops: \", len(rural_stops))\n",
    "\n",
    "limited_transfers = transfer_stops[(transfer_stops.transfer_walk_time < 0.2) | \n",
    "                                   (transfer_stops.stop_id_x.isin(rural_stops)) | \n",
    "                                   (transfer_stops.stop_id_y.isin(rural_stops))]\n",
    "limited_transfers = limited_transfers[['stop_id_x', 'stop_id_y', 'transfer_walk_time']]\n",
    "limited_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminate_early_depart_late_arrive(trips, stop_id_col_name='final_stop_id',\n",
    "                                       dep_time_col_name='adj_journey_dep_time', \n",
    "                                       arr_time_col_name='journey_arrival_time'):\n",
    "    ## This function eliminates trips where there is another trip which leaves later and arrives at the same place earlier\n",
    "    ## Start by sorting the df of trips by stop_id, arrival_time, and adj_dep_time\n",
    "    \n",
    "    trips = trips.sort_values([stop_id_col_name, arr_time_col_name, dep_time_col_name],\n",
    "                               ascending=[True, True, False])\n",
    "\n",
    "    ## The following loop retains the first occurence of every stop_id (i.e. the one with the latest departure time)\n",
    "    ## Subsequent occurences are ordered in decreasing departure time, \n",
    "    ## and are retained only of their arrival time is earlier than the one above\n",
    "    \n",
    "    ## This needs to be repeated until all early depart/late arrive trips have been removed\n",
    "    \n",
    "    while True:\n",
    "        initial_len = len(trips.index)\n",
    "        trips = trips[(~trips[stop_id_col_name].duplicated()) | \n",
    "                      (trips[dep_time_col_name].diff() > 0)]\n",
    "        new_len = len(trips.index)\n",
    "\n",
    "        if initial_len == new_len:\n",
    "            return trips\n",
    "\n",
    "def remove_walkable_trips(trips, threshold=0.1):\n",
    "    ## Removes any trips that can be completed faster on foot\n",
    "    ## Also removes trips that take longer on foot up to a given threshold (in hours)\n",
    "    \n",
    "    trips = pd.merge(trips, vax_hub_stops, left_on='final_stop_id', right_on='stop_id')\n",
    "    direct_to_stop_time = (1 + WALK_EFFORT_FACTOR) * trips['stop_to_vax_hub_time']\n",
    "    transit_journey_time = trips['journey_arrival_time'] - trips['adj_journey_dep_time']\n",
    "    trips = trips[direct_to_stop_time > transit_journey_time + threshold]\n",
    "    trips = trips.drop(columns=vax_hub_stops.columns)\n",
    "    return trips\n",
    "\n",
    "def eliminate_back_track(current_trips, extended_terminated_trips):\n",
    "    current_trips['terminated'] = False\n",
    "    for df in extended_terminated_trips:\n",
    "        df['terminated'] = True\n",
    "        current_trips = pd.concat([current_trips, df])\n",
    "    \n",
    "    current_trips = eliminate_early_depart_late_arrive(current_trips)\n",
    "    current_trips = current_trips[~current_trips.terminated]\n",
    "    \n",
    "    return current_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTT:  0.6044955253601074 3.7562146186828613\n",
      "4.478371858596802 0.3169722557067871\n"
     ]
    }
   ],
   "source": [
    "def compute_first_legs(): \n",
    "    local_stops = vax_hub_stops[vax_hub_stops.stop_to_vax_hub_distance < MAX_WALK_DIST]\n",
    "    local_stops = local_stops[['stop_id', 'stop_to_vax_hub_time', 'Facility']]    \n",
    "        \n",
    "    first_legs = pd.merge(local_stops, departures, on='stop_id')\n",
    "    first_legs = first_legs.rename(columns={'departure_time_hrs': 'leg_1_departure_time', \n",
    "                                            'stop_id': 'stop_1a_id', \n",
    "                                            'stop_to_vax_hub_time': 'walk_1_time',\n",
    "                                            'Facility': 'departure_facility'})\n",
    "    \n",
    "    first_legs['journey_dep_time'] = first_legs['leg_1_departure_time'] - first_legs['walk_1_time']\n",
    "    first_legs['total_walk_time'] = first_legs['walk_1_time']\n",
    "    first_legs['adj_journey_dep_time'] = first_legs['journey_dep_time'] - WALK_EFFORT_FACTOR * first_legs['total_walk_time']\n",
    "    \n",
    "    first_legs = pd.merge(first_legs, arrivals, on='trip_id')\n",
    "\n",
    "    first_legs = first_legs[first_legs.stop_sequence_y > first_legs.stop_sequence_x]\n",
    "    \n",
    "    first_legs = first_legs.rename(columns={'trip_id': 'leg_1_trip_id',\n",
    "                                            'arrival_time_hrs': 'leg_1_arrival_time',\n",
    "                                            'stop_id': 'stop_1b_id'})\n",
    "\n",
    "    first_legs['journey_arrival_time'] = first_legs['leg_1_arrival_time']\n",
    "    first_legs['final_stop_id'] = first_legs['stop_1b_id']\n",
    "    \n",
    "    first_legs = first_legs[['departure_facility', 'total_walk_time', 'journey_dep_time',\n",
    "                             'journey_arrival_time', 'adj_journey_dep_time', 'final_stop_id', \n",
    "                             'walk_1_time', 'stop_1a_id', 'leg_1_trip_id', \n",
    "                             'leg_1_departure_time', 'leg_1_arrival_time', 'stop_1b_id']]\n",
    "    \n",
    "    first_legs = eliminate_early_depart_late_arrive(first_legs)\n",
    "    first_legs = remove_walkable_trips(first_legs)\n",
    "    \n",
    "    return first_legs\n",
    "\n",
    "first_legs = compute_first_legs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_transfer_stops(trips, connected_stops, leg_number):\n",
    "    ## Extends the trips DataFrame by finding all stops within walking distance of the current stops\n",
    "    \n",
    "    ## connected_stops.columns = ['stop_id_x', 'stop_id_y', 'transfer_walk_time']\n",
    "    \n",
    "    trips = pd.merge(trips, connected_stops, left_on='final_stop_id', right_on='stop_id_x').drop(columns='stop_id_x')\n",
    "    \n",
    "    trips['final_stop_id'] = trips['stop_id_y']\n",
    "    \n",
    "    prev_arrival_time = 'leg_' + str(leg_number-1) + '_arrival_time'\n",
    "    trips['journey_arrival_time'] = trips[prev_arrival_time] + trips['transfer_walk_time']\n",
    "    \n",
    "    trips['total_walk_time'] += trips['transfer_walk_time']\n",
    "    trips['adj_journey_dep_time'] = trips['journey_dep_time'] - WALK_EFFORT_FACTOR * trips['total_walk_time']\n",
    "    \n",
    "    col_names = {'stop_id_y': 'stop_' + str(leg_number) + 'a_id',\n",
    "                 'transfer_walk_time': 'walk_' + str(leg_number) + '_time'}\n",
    "    trips = trips.rename(columns=col_names)\n",
    "\n",
    "    trips = eliminate_early_depart_late_arrive(trips)\n",
    "    \n",
    "    trips = remove_walkable_trips(trips)\n",
    "    \n",
    "    return trips\n",
    "\n",
    "def get_departures(trips, leg_number, min_transfer_time=0.1, chunk_size=None):\n",
    "    if chunk_size == None:\n",
    "        chunk_size = len(trips.index)\n",
    "        \n",
    "    lower_bound = 0\n",
    "    dfs = []\n",
    "    \n",
    "    while lower_bound < len(trips.index):\n",
    "        upper_bound = min(lower_bound + chunk_size, len(trips.index))\n",
    "        \n",
    "        df = trips[lower_bound:upper_bound]    \n",
    "        df = pd.merge(df, departures, left_on='final_stop_id', right_on='stop_id').drop(columns='stop_id')\n",
    "        df = df[df.departure_time_hrs > df.journey_arrival_time]\n",
    "        df = df.sort_values(['trip_id', 'adj_journey_dep_time', 'stop_sequence'],\n",
    "                            ascending=[False, False, True])\n",
    "\n",
    "        duplicate_vals = True\n",
    "        while duplicate_vals:\n",
    "            initial_len = len(df.index)\n",
    "            df = df[(~df['trip_id'].duplicated()) | \n",
    "                  (df['stop_sequence'].diff() < -1)]\n",
    "            new_len = len(df.index)\n",
    "\n",
    "            if initial_len == new_len:\n",
    "                duplicate_vals = False\n",
    "        \n",
    "        dfs.append(df)\n",
    "        lower_bound += chunk_size\n",
    "    \n",
    "    df = pd.concat(dfs)\n",
    "    \n",
    "    duplicate_vals = True\n",
    "    while duplicate_vals:\n",
    "        initial_len = len(df.index)\n",
    "        df = df[(~df['trip_id'].duplicated()) | \n",
    "              (df['stop_sequence'].diff() < -1)]\n",
    "        new_len = len(df.index)\n",
    "\n",
    "        if initial_len == new_len:\n",
    "            duplicate_vals = False\n",
    "    \n",
    "    df = df.rename(columns={'trip_id': 'leg_' + str(leg_number) + '_trip_id',\n",
    "                            'departure_time_hrs': 'leg_' + str(leg_number) + '_departure_time'})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arrivals(trips, leg_number, chunk_size=None):\n",
    "    trip_col = 'leg_' + str(leg_number) + '_trip_id'\n",
    "    \n",
    "    arrival_time_col = 'leg_' + str(leg_number) + '_arrival_time'\n",
    "    arrival_stop_col = 'stop_' + str(leg_number) + 'b_id'\n",
    "    \n",
    "    df = pd.merge(trips, arrivals, left_on='leg_' + str(leg_number) + '_trip_id', right_on='trip_id').drop(columns='trip_id')\n",
    "    df = df[df.stop_sequence_y > df.stop_sequence_x]\n",
    "    df = df.drop(columns=['stop_sequence_x', 'stop_sequence_y'])\n",
    "    df = df.rename(columns={'arrival_time_hrs': arrival_time_col,\n",
    "                            'stop_id': arrival_stop_col})\n",
    "    df['journey_arrival_time'] = df[arrival_time_col]\n",
    "    df['final_stop_id'] = df[arrival_stop_col]\n",
    "\n",
    "    df = eliminate_early_depart_late_arrive(df)\n",
    "    df = remove_walkable_trips(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTT:  3.121650457382202 10.718326330184937\n",
      "2 509480\n",
      "2 31550\n",
      "TTT:  0.3101694583892822 0.31914424896240234\n",
      "2 126632\n",
      "TTT:  1.3912758827209473 0.7988648414611816\n",
      "2 60746\n",
      "TTT:  2.2051544189453125 4.677961826324463\n",
      "3 334466\n",
      "3 31053\n",
      "TTT:  0.29720354080200195 0.35505032539367676\n",
      "3 113418\n",
      "TTT:  2.075670003890991 1.092104434967041\n",
      "3 34399\n",
      "TTT:  1.1087119579315186 2.0592610836029053\n",
      "4 206200\n",
      "4 25703\n",
      "TTT:  0.31054186820983887 0.3370983600616455\n",
      "4 92678\n",
      "TTT:  2.4635813236236572 1.5827605724334717\n",
      "4 22621\n",
      "TTT:  0.837775468826294 2.1829609870910645\n",
      "5 133084\n",
      "5 21912\n",
      "TTT:  0.31615495681762695 0.4278550148010254\n",
      "5 79329\n",
      "TTT:  2.4104464054107666 1.6642510890960693\n",
      "5 11744\n"
     ]
    }
   ],
   "source": [
    "legs = [first_legs]\n",
    "terminated_trips = []\n",
    "\n",
    "\n",
    "for leg_number in range(2, 6):\n",
    "    leg_dep_stops = identify_transfer_stops(legs[-1], limited_transfers, leg_number)\n",
    "    legs.append(leg_dep_stops)\n",
    "    terminated_trips.append(leg_dep_stops)\n",
    "    print(leg_number, len(leg_dep_stops.index))\n",
    "\n",
    "    leg_departures = get_departures(legs[-1], leg_number, chunk_size=20000)\n",
    "    legs.append(leg_departures)\n",
    "    print(leg_number, len(legs[-1].index))\n",
    "\n",
    "    leg_arrivals = get_arrivals(legs[-1], leg_number)\n",
    "    print(leg_number, len(leg_arrivals.index))\n",
    "    leg_arrivals = eliminate_back_track(leg_arrivals, terminated_trips)\n",
    "    legs.append(leg_arrivals)\n",
    "    print(leg_number, len(legs[-1].index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departure_facility</th>\n",
       "      <th>total_walk_time</th>\n",
       "      <th>journey_dep_time</th>\n",
       "      <th>journey_arrival_time</th>\n",
       "      <th>adj_journey_dep_time</th>\n",
       "      <th>final_stop_id</th>\n",
       "      <th>walk_1_time</th>\n",
       "      <th>stop_1a_id</th>\n",
       "      <th>leg_1_trip_id</th>\n",
       "      <th>leg_1_departure_time</th>\n",
       "      <th>...</th>\n",
       "      <th>leg_2_departure_time</th>\n",
       "      <th>stop_2b_id</th>\n",
       "      <th>leg_2_arrival_time</th>\n",
       "      <th>terminated</th>\n",
       "      <th>stop_3a_id</th>\n",
       "      <th>walk_3_time</th>\n",
       "      <th>leg_3_trip_id</th>\n",
       "      <th>leg_3_departure_time</th>\n",
       "      <th>stop_3b_id</th>\n",
       "      <th>leg_3_arrival_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fairways Hotel</td>\n",
       "      <td>0.106272</td>\n",
       "      <td>13.852061</td>\n",
       "      <td>15.383333</td>\n",
       "      <td>13.798925</td>\n",
       "      <td>700000000229</td>\n",
       "      <td>0.106272</td>\n",
       "      <td>8300B133581</td>\n",
       "      <td>1470845.14.10-168-e19-1.489.I</td>\n",
       "      <td>13.958333</td>\n",
       "      <td>...</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>7000B156051</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>False</td>\n",
       "      <td>7000B156051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1470785.14.10-160-e19-1.440.I</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>700000000229</td>\n",
       "      <td>15.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Letterkenny Institute of Technology</td>\n",
       "      <td>0.044849</td>\n",
       "      <td>15.331168</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>15.308744</td>\n",
       "      <td>700000013460</td>\n",
       "      <td>0.035498</td>\n",
       "      <td>8530B1559601</td>\n",
       "      <td>1414937.7.10-32-e19-1.91.I</td>\n",
       "      <td>15.366667</td>\n",
       "      <td>...</td>\n",
       "      <td>16.416667</td>\n",
       "      <td>8530B1522701</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>False</td>\n",
       "      <td>8530B152491</td>\n",
       "      <td>0.009351</td>\n",
       "      <td>1475896.14.10-494-e19-1.2049.I</td>\n",
       "      <td>16.683333</td>\n",
       "      <td>700000013460</td>\n",
       "      <td>16.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Aviva Stadium</td>\n",
       "      <td>0.055799</td>\n",
       "      <td>13.200615</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>13.172716</td>\n",
       "      <td>700000014719</td>\n",
       "      <td>0.032718</td>\n",
       "      <td>822GIR0133</td>\n",
       "      <td>214.TA.99-13-r11-1.3.O</td>\n",
       "      <td>13.233333</td>\n",
       "      <td>...</td>\n",
       "      <td>13.266667</td>\n",
       "      <td>822GIR0025</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>8220DB000407</td>\n",
       "      <td>0.023080</td>\n",
       "      <td>9.daily.8-400-y11-1.1.O</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>700000014719</td>\n",
       "      <td>15.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aviva Stadium</td>\n",
       "      <td>0.055799</td>\n",
       "      <td>14.200615</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>14.172716</td>\n",
       "      <td>700000014719</td>\n",
       "      <td>0.032718</td>\n",
       "      <td>822GIR0133</td>\n",
       "      <td>217.TA.99-13-r11-1.3.O</td>\n",
       "      <td>14.233333</td>\n",
       "      <td>...</td>\n",
       "      <td>14.266667</td>\n",
       "      <td>822GIR0025</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>False</td>\n",
       "      <td>8220DB000407</td>\n",
       "      <td>0.023080</td>\n",
       "      <td>10.daily.8-400-y11-1.1.O</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>700000014719</td>\n",
       "      <td>16.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Aviva Stadium</td>\n",
       "      <td>0.055799</td>\n",
       "      <td>15.283948</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>15.256049</td>\n",
       "      <td>700000014719</td>\n",
       "      <td>0.032718</td>\n",
       "      <td>822GIR0133</td>\n",
       "      <td>1005.TA.99-13-r11-1.10.O</td>\n",
       "      <td>15.316667</td>\n",
       "      <td>...</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>822GIR0025</td>\n",
       "      <td>15.416667</td>\n",
       "      <td>False</td>\n",
       "      <td>8220DB000407</td>\n",
       "      <td>0.023080</td>\n",
       "      <td>11.daily.8-400-y11-1.1.O</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>700000014719</td>\n",
       "      <td>17.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157071</th>\n",
       "      <td>Letterkenny Institute of Technology</td>\n",
       "      <td>0.104140</td>\n",
       "      <td>14.049661</td>\n",
       "      <td>17.583333</td>\n",
       "      <td>13.997592</td>\n",
       "      <td>gen:57402:7996:0:1</td>\n",
       "      <td>0.033672</td>\n",
       "      <td>8530B158221</td>\n",
       "      <td>2.Sat.3-931-y11-2.7.I</td>\n",
       "      <td>14.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>15.166667</td>\n",
       "      <td>853000122</td>\n",
       "      <td>15.916667</td>\n",
       "      <td>False</td>\n",
       "      <td>853000121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.daily.49-954-y11-1.1.O</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>gen:57402:7996:0:1</td>\n",
       "      <td>17.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157074</th>\n",
       "      <td>Letterkenny Institute of Technology</td>\n",
       "      <td>0.105214</td>\n",
       "      <td>14.049661</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>13.997055</td>\n",
       "      <td>gen:57402:8178:0:1</td>\n",
       "      <td>0.033672</td>\n",
       "      <td>8530B158221</td>\n",
       "      <td>2.Sat.3-931-y11-2.7.I</td>\n",
       "      <td>14.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>15.166667</td>\n",
       "      <td>853000122</td>\n",
       "      <td>15.916667</td>\n",
       "      <td>False</td>\n",
       "      <td>853000124</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>6.Mo-Sa.49-955-y11-2.5.I</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>gen:57402:8178:0:1</td>\n",
       "      <td>18.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157075</th>\n",
       "      <td>Letterkenny Institute of Technology</td>\n",
       "      <td>0.105214</td>\n",
       "      <td>14.049661</td>\n",
       "      <td>18.050000</td>\n",
       "      <td>13.997055</td>\n",
       "      <td>gen:57402:8179:0:1</td>\n",
       "      <td>0.033672</td>\n",
       "      <td>8530B158221</td>\n",
       "      <td>2.Sat.3-931-y11-2.7.I</td>\n",
       "      <td>14.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>15.166667</td>\n",
       "      <td>853000122</td>\n",
       "      <td>15.916667</td>\n",
       "      <td>False</td>\n",
       "      <td>853000124</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>6.Mo-Sa.49-955-y11-2.5.I</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>gen:57402:8179:0:1</td>\n",
       "      <td>18.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157076</th>\n",
       "      <td>Letterkenny Institute of Technology</td>\n",
       "      <td>0.131984</td>\n",
       "      <td>15.414502</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>15.348510</td>\n",
       "      <td>gen:57402:81:0:1</td>\n",
       "      <td>0.035498</td>\n",
       "      <td>8530B1559601</td>\n",
       "      <td>1414841.7.10-64-e19-1.174.I</td>\n",
       "      <td>15.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>853000360</td>\n",
       "      <td>17.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>853000360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.Mo-Sa.3-957-y11-1.6.H</td>\n",
       "      <td>17.916667</td>\n",
       "      <td>gen:57402:81:0:1</td>\n",
       "      <td>18.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157080</th>\n",
       "      <td>Letterkenny Institute of Technology</td>\n",
       "      <td>0.117083</td>\n",
       "      <td>17.632995</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>17.574453</td>\n",
       "      <td>gen:57402:8244:0:1</td>\n",
       "      <td>0.033672</td>\n",
       "      <td>8530B158221</td>\n",
       "      <td>6.Mo-Sa.49-953-y11-1.3.I</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>18.583333</td>\n",
       "      <td>7000B158131</td>\n",
       "      <td>18.833333</td>\n",
       "      <td>False</td>\n",
       "      <td>gen:31400:8241:0:1</td>\n",
       "      <td>0.026026</td>\n",
       "      <td>4.Sat.3-931-y11-2.8.O</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>gen:57402:8244:0:1</td>\n",
       "      <td>19.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34399 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         departure_facility  total_walk_time  \\\n",
       "0                            Fairways Hotel         0.106272   \n",
       "10      Letterkenny Institute of Technology         0.044849   \n",
       "13                            Aviva Stadium         0.055799   \n",
       "14                            Aviva Stadium         0.055799   \n",
       "15                            Aviva Stadium         0.055799   \n",
       "...                                     ...              ...   \n",
       "157071  Letterkenny Institute of Technology         0.104140   \n",
       "157074  Letterkenny Institute of Technology         0.105214   \n",
       "157075  Letterkenny Institute of Technology         0.105214   \n",
       "157076  Letterkenny Institute of Technology         0.131984   \n",
       "157080  Letterkenny Institute of Technology         0.117083   \n",
       "\n",
       "        journey_dep_time  journey_arrival_time  adj_journey_dep_time  \\\n",
       "0              13.852061             15.383333             13.798925   \n",
       "10             15.331168             16.750000             15.308744   \n",
       "13             13.200615             15.333333             13.172716   \n",
       "14             14.200615             16.333333             14.172716   \n",
       "15             15.283948             17.333333             15.256049   \n",
       "...                  ...                   ...                   ...   \n",
       "157071         14.049661             17.583333             13.997592   \n",
       "157074         14.049661             18.250000             13.997055   \n",
       "157075         14.049661             18.050000             13.997055   \n",
       "157076         15.414502             18.166667             15.348510   \n",
       "157080         17.632995             19.250000             17.574453   \n",
       "\n",
       "             final_stop_id  walk_1_time    stop_1a_id  \\\n",
       "0             700000000229     0.106272   8300B133581   \n",
       "10            700000013460     0.035498  8530B1559601   \n",
       "13            700000014719     0.032718    822GIR0133   \n",
       "14            700000014719     0.032718    822GIR0133   \n",
       "15            700000014719     0.032718    822GIR0133   \n",
       "...                    ...          ...           ...   \n",
       "157071  gen:57402:7996:0:1     0.033672   8530B158221   \n",
       "157074  gen:57402:8178:0:1     0.033672   8530B158221   \n",
       "157075  gen:57402:8179:0:1     0.033672   8530B158221   \n",
       "157076    gen:57402:81:0:1     0.035498  8530B1559601   \n",
       "157080  gen:57402:8244:0:1     0.033672   8530B158221   \n",
       "\n",
       "                        leg_1_trip_id  leg_1_departure_time  ...  \\\n",
       "0       1470845.14.10-168-e19-1.489.I             13.958333  ...   \n",
       "10         1414937.7.10-32-e19-1.91.I             15.366667  ...   \n",
       "13             214.TA.99-13-r11-1.3.O             13.233333  ...   \n",
       "14             217.TA.99-13-r11-1.3.O             14.233333  ...   \n",
       "15           1005.TA.99-13-r11-1.10.O             15.316667  ...   \n",
       "...                               ...                   ...  ...   \n",
       "157071          2.Sat.3-931-y11-2.7.I             14.083333  ...   \n",
       "157074          2.Sat.3-931-y11-2.7.I             14.083333  ...   \n",
       "157075          2.Sat.3-931-y11-2.7.I             14.083333  ...   \n",
       "157076    1414841.7.10-64-e19-1.174.I             15.450000  ...   \n",
       "157080       6.Mo-Sa.49-953-y11-1.3.I             17.666667  ...   \n",
       "\n",
       "        leg_2_departure_time    stop_2b_id leg_2_arrival_time  terminated  \\\n",
       "0                  14.500000   7000B156051          15.083333       False   \n",
       "10                 16.416667  8530B1522701          16.500000       False   \n",
       "13                 13.266667    822GIR0025          13.333333       False   \n",
       "14                 14.266667    822GIR0025          14.333333       False   \n",
       "15                 15.350000    822GIR0025          15.416667       False   \n",
       "...                      ...           ...                ...         ...   \n",
       "157071             15.166667     853000122          15.916667       False   \n",
       "157074             15.166667     853000122          15.916667       False   \n",
       "157075             15.166667     853000122          15.916667       False   \n",
       "157076             17.166667     853000360          17.833333       False   \n",
       "157080             18.583333   7000B158131          18.833333       False   \n",
       "\n",
       "                stop_3a_id  walk_3_time                   leg_3_trip_id  \\\n",
       "0              7000B156051     0.000000   1470785.14.10-160-e19-1.440.I   \n",
       "10             8530B152491     0.009351  1475896.14.10-494-e19-1.2049.I   \n",
       "13            8220DB000407     0.023080         9.daily.8-400-y11-1.1.O   \n",
       "14            8220DB000407     0.023080        10.daily.8-400-y11-1.1.O   \n",
       "15            8220DB000407     0.023080        11.daily.8-400-y11-1.1.O   \n",
       "...                    ...          ...                             ...   \n",
       "157071           853000121     0.000000        4.daily.49-954-y11-1.1.O   \n",
       "157074           853000124     0.001074        6.Mo-Sa.49-955-y11-2.5.I   \n",
       "157075           853000124     0.001074        6.Mo-Sa.49-955-y11-2.5.I   \n",
       "157076           853000360     0.000000         9.Mo-Sa.3-957-y11-1.6.H   \n",
       "157080  gen:31400:8241:0:1     0.026026           4.Sat.3-931-y11-2.8.O   \n",
       "\n",
       "        leg_3_departure_time          stop_3b_id leg_3_arrival_time  \n",
       "0                  15.250000        700000000229          15.383333  \n",
       "10                 16.683333        700000013460          16.750000  \n",
       "13                 13.500000        700000014719          15.333333  \n",
       "14                 14.500000        700000014719          16.333333  \n",
       "15                 15.500000        700000014719          17.333333  \n",
       "...                      ...                 ...                ...  \n",
       "157071             17.000000  gen:57402:7996:0:1          17.583333  \n",
       "157074             17.500000  gen:57402:8178:0:1          18.250000  \n",
       "157075             17.500000  gen:57402:8179:0:1          18.050000  \n",
       "157076             17.916667    gen:57402:81:0:1          18.166667  \n",
       "157080             19.000000  gen:57402:8244:0:1          19.250000  \n",
       "\n",
       "[34399 rows x 25 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legs[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_first_legs_from_facility_dep(facility):\n",
    "    ## This finds all trips that can be make with a single leg from the stops closest to a given vaccine centre\n",
    "    \n",
    "    local_stops = vax_hub_stops[vax_hub_stops.Facility == facility] # All stops that are closer to this facility than any other\n",
    "    local_stops = local_stops[local_stops.stop_to_vax_hub_distance < MAX_WALK_DIST]\n",
    "    local_stops = local_stops[['stop_id', 'stop_to_vax_hub_time']]\n",
    "    \n",
    "    \n",
    "    first_legs_from_facility = pd.merge(local_stops, departures, on='stop_id')\n",
    "    first_legs_from_facility = first_legs_from_facility.rename(columns={'departure_time_hrs': 'leg_1_departure_time', \n",
    "                                                                        'stop_id': 'stop_1a_id', \n",
    "                                                                        'stop_to_vax_hub_time': 'walk_1_time'})\n",
    "    \n",
    "    first_legs_from_facility = first_legs_from_facility.sort_values('walk_1_time')\n",
    "    first_legs_from_facility = first_legs_from_facility.drop_duplicates('trip_id')  # some trips will appear multiple times, each starting from a different stop\n",
    "    \n",
    "    first_legs_from_facility['journey_dep_time'] = first_legs_from_facility['leg_1_departure_time'] - first_legs_from_facility['walk_1_time']\n",
    "    first_legs_from_facility['total_walk_time'] = first_legs_from_facility['walk_1_time']\n",
    "    first_legs_from_facility['adj_journey_dep_time'] = first_legs_from_facility['journey_dep_time'] - WALK_EFFORT_FACTOR * first_legs_from_facility['total_walk_time']\n",
    "    \n",
    "    t3 = time.time()\n",
    "    first_legs_from_facility = pd.merge(first_legs_from_facility, arrivals, on='trip_id')\n",
    "    first_legs_from_facility['departure_facility'] = facility\n",
    "    '''\n",
    "    first_legs_from_facility = first_legs_from_facility[first_legs_from_facility.stop_sequence_y > first_legs_from_facility.stop_sequence_x]\n",
    "    print(str(len(first_legs_from_facility.index)) + ' +')\n",
    "\n",
    "    first_legs_from_facility = first_legs_from_facility.rename(columns={'trip_id': 'leg_1_trip_id', \n",
    "                                                                        'arrival_time_hrs': 'leg_1_arrival_time', \n",
    "                                                                        'stop_id': 'stop_1b_id'})\n",
    "\n",
    "    first_legs_from_facility['journey_arrival_time'] = first_legs_from_facility['leg_1_arrival_time']\n",
    "    first_legs_from_facility['final_stop_id'] = first_legs_from_facility['stop_1b_id']\n",
    "    \n",
    "\n",
    "    first_legs_from_facility = first_legs_from_facility[['departure_facility', 'total_walk_time', 'journey_dep_time', \n",
    "                                                         'journey_arrival_time', 'adj_journey_dep_time', 'final_stop_id', \n",
    "                                                         'walk_1_time', 'stop_1a_id', 'leg_1_trip_id', \n",
    "                                                         'leg_1_departure_time', 'leg_1_arrival_time', 'stop_1b_id']]\n",
    "    \n",
    "    #first_legs_from_facility = eliminate_early_depart_late_arrive(first_legs_from_facility)\n",
    "    #first_legs_from_facility = remove_walkable_trips(first_legs_from_facility)\n",
    "    '''\n",
    "    return first_legs_from_facility\n",
    "\n",
    "def compute_first_legs_dep():\n",
    "    t1 = time.time()\n",
    "    first_legs = []\n",
    "\n",
    "    facilities = vax_hub_stops['Facility'].unique()\n",
    "    for facility in facilities:\n",
    "        first_legs_from_facility = compute_first_legs_from_facility(facility)\n",
    "        first_legs.append(first_legs_from_facility) \n",
    "    all_first_legs = pd.concat(first_legs)\n",
    "    #all_first_legs = eliminate_early_depart_late_arrive(all_first_legs)\n",
    "    #all_first_legs = remove_walkable_trips(all_first_legs)\n",
    "    return all_first_legs\n",
    "\n",
    "\n",
    "#first_legs_old = compute_first_legs()\n",
    "#first_legs_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearby_stops2(stops):\n",
    "    t1 = time.time()\n",
    "    ## Returns a dataframe containing all pairs of stops that are within walking distance of each other\n",
    "    ## This function works by dividing the region into cells, each containing 0.1 degrees of longitude and latitude\n",
    "    ## Stops are paired if they are in the same or neighbouring cell (including diagonal neighbours)\n",
    "    ## For Ireland, 0.1 degrees longitude is about 6.6 kms, while 0.1 degrees latitude is about 11.1 kms\n",
    "    ## So this function will identify every pair of stops that are less than 6.6 kms apart\n",
    "        \n",
    "    decimals = 1\n",
    "    round_precision = 0.1  # degrees longitude/latitude\n",
    "    middle = round_precision / 2\n",
    "    \n",
    "    rounded_stops = stops.copy()\n",
    "    \n",
    "    ## lat_ceil, lat_floor, lon_ceil, lon_floor are the lat/lon values of the four edges of the cell\n",
    "    rounded_stops['lat_ceil'] = rounded_stops['stop_lat'] + middle\n",
    "    rounded_stops['lat_ceil'] = rounded_stops['lat_ceil'].round(decimals)\n",
    "\n",
    "    rounded_stops['lon_ceil'] = rounded_stops['stop_lon'] + middle\n",
    "    rounded_stops['lon_ceil'] = rounded_stops['lon_ceil'].round(decimals)\n",
    "\n",
    "    rounded_stops['lat_floor'] = rounded_stops['lat_ceil'] - round_precision\n",
    "    rounded_stops['lon_floor'] = rounded_stops['lon_ceil'] - round_precision\n",
    "        \n",
    "    cell_edges = []\n",
    "    \n",
    "    for lat_round in ['ceil', 'floor']:\n",
    "        for lon_round in ['ceil', 'floor']:\n",
    "            df = rounded_stops[['stop_id', 'lat_' + lat_round, 'lon_' + lon_round, 'stop_lat', 'stop_lon']]\n",
    "            df = df.rename(columns={'lat_' + lat_round: 'rounded_lat',\n",
    "                                    'lon_' + lon_round: 'rounded_lon'})\n",
    "            \n",
    "            cell_edges.append(df)\n",
    "    \n",
    "    \n",
    "    print(\"NEXT\")\n",
    "    \n",
    "    rounded_stops = pd.concat(cell_edges)\n",
    "    print(\"CONCAT\")\n",
    "    \n",
    "    rounded_stops_copy = rounded_stops.copy()\n",
    "    \n",
    "    print(\"MERGE START\")\n",
    "    nearby_stops = pd.merge(rounded_stops, rounded_stops_copy, on=['rounded_lat', 'rounded_lon'])\n",
    "    print(\"END\")\n",
    "    \n",
    "    nearby_stops = nearby_stops.drop_duplicates(['stop_id_x', 'stop_id_y'])\n",
    "    t2 = time.time()\n",
    "    print(t2-t1, len(nearby_stops.index))\n",
    "    return nearby_stops\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
